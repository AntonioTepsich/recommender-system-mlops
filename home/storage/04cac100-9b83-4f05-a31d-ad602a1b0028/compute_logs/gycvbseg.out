2024-03-01 19:53:12 [46mplatform[0m > Docker volume job log path: /tmp/workspace/71/0/logs.log
2024-03-01 19:53:12 [46mplatform[0m > Executing worker wrapper. Airbyte version: 0.50.47
2024-03-01 19:53:12 [46mplatform[0m > Attempt 0 to save workflow id for cancellation
2024-03-01 19:53:12 [46mplatform[0m > start sync worker. job id: 71 attempt id: 0
2024-03-01 19:53:12 [46mplatform[0m > 
2024-03-01 19:53:12 [46mplatform[0m > ----- START REPLICATION -----
2024-03-01 19:53:12 [46mplatform[0m > 
2024-03-01 19:53:12 [46mplatform[0m > Running destination...
2024-03-01 19:53:12 [46mplatform[0m > Using default value for environment variable SIDECAR_KUBE_CPU_LIMIT: '2.0'
2024-03-01 19:53:12 [46mplatform[0m > Using default value for environment variable SOCAT_KUBE_CPU_LIMIT: '2.0'
2024-03-01 19:53:12 [46mplatform[0m > Using default value for environment variable SIDECAR_KUBE_CPU_LIMIT: '2.0'
2024-03-01 19:53:12 [46mplatform[0m > Using default value for environment variable SIDECAR_KUBE_CPU_REQUEST: '0.1'
2024-03-01 19:53:12 [46mplatform[0m > Using default value for environment variable SOCAT_KUBE_CPU_LIMIT: '2.0'
2024-03-01 19:53:12 [46mplatform[0m > Using default value for environment variable SOCAT_KUBE_CPU_REQUEST: '0.1'
2024-03-01 19:53:12 [46mplatform[0m > Using default value for environment variable LAUNCHDARKLY_KEY: ''
2024-03-01 19:53:12 [46mplatform[0m > Using default value for environment variable SIDECAR_KUBE_CPU_REQUEST: '0.1'
2024-03-01 19:53:12 [46mplatform[0m > Using default value for environment variable SOCAT_KUBE_CPU_REQUEST: '0.1'
2024-03-01 19:53:12 [46mplatform[0m > Using default value for environment variable LAUNCHDARKLY_KEY: ''
2024-03-01 19:53:12 [46mplatform[0m > Checking if airbyte/source-file:0.3.15 exists...
2024-03-01 19:53:12 [46mplatform[0m > Checking if airbyte/destination-postgres:0.4.0 exists...
2024-03-01 19:53:12 [46mplatform[0m > airbyte/destination-postgres:0.4.0 was found locally.
2024-03-01 19:53:12 [46mplatform[0m > Creating docker container = destination-postgres-write-71-0-zhkgk with resources io.airbyte.config.ResourceRequirements@3ac79a1e[cpuRequest=0.5,cpuLimit=1,memoryRequest=1Gi,memoryLimit=2Gi,additionalProperties={}] and allowedHosts null
2024-03-01 19:53:12 [46mplatform[0m > Preparing command: docker run --rm --init -i -w /data/71/0 --log-driver none --name destination-postgres-write-71-0-zhkgk --network host -v airbyte_workspace:/data -v /tmp/airbyte_local:/local -e DEPLOYMENT_MODE=OSS -e WORKER_CONNECTOR_IMAGE=airbyte/destination-postgres:0.4.0 -e AUTO_DETECT_SCHEMA=true -e LAUNCHDARKLY_KEY= -e SOCAT_KUBE_CPU_REQUEST=0.1 -e SOCAT_KUBE_CPU_LIMIT=2.0 -e FIELD_SELECTION_WORKSPACES= -e USE_STREAM_CAPABLE_STATE=true -e AIRBYTE_ROLE=dev -e WORKER_ENVIRONMENT=DOCKER -e APPLY_FIELD_SELECTION=false -e WORKER_JOB_ATTEMPT=0 -e OTEL_COLLECTOR_ENDPOINT=http://host.docker.internal:4317 -e FEATURE_FLAG_CLIENT=config -e AIRBYTE_VERSION=0.50.47 -e WORKER_JOB_ID=71 --cpus=1 --memory-reservation=1Gi --memory=2Gi airbyte/destination-postgres:0.4.0 write --config destination_config.json --catalog destination_catalog.json
2024-03-01 19:53:12 [46mplatform[0m > airbyte/source-file:0.3.15 was found locally.
2024-03-01 19:53:12 [46mplatform[0m > Creating docker container = source-file-read-71-0-eakav with resources io.airbyte.config.ResourceRequirements@55cf6fe5[cpuRequest=0.5,cpuLimit=1,memoryRequest=1Gi,memoryLimit=2Gi,additionalProperties={}] and allowedHosts io.airbyte.config.AllowedHosts@3c31a622[hosts=[*, *.datadoghq.com, *.datadoghq.eu, *.sentry.io],additionalProperties={}]
2024-03-01 19:53:12 [46mplatform[0m > Writing messages to protocol version 0.2.0
2024-03-01 19:53:12 [46mplatform[0m > Preparing command: docker run --rm --init -i -w /data/71/0 --log-driver none --name source-file-read-71-0-eakav -e CONCURRENT_SOURCE_STREAM_READ=false --network host -v airbyte_workspace:/data -v /tmp/airbyte_local:/local -e DEPLOYMENT_MODE=OSS -e WORKER_CONNECTOR_IMAGE=airbyte/source-file:0.3.15 -e AUTO_DETECT_SCHEMA=true -e LAUNCHDARKLY_KEY= -e SOCAT_KUBE_CPU_REQUEST=0.1 -e SOCAT_KUBE_CPU_LIMIT=2.0 -e FIELD_SELECTION_WORKSPACES= -e USE_STREAM_CAPABLE_STATE=true -e AIRBYTE_ROLE=dev -e WORKER_ENVIRONMENT=DOCKER -e APPLY_FIELD_SELECTION=false -e WORKER_JOB_ATTEMPT=0 -e OTEL_COLLECTOR_ENDPOINT=http://host.docker.internal:4317 -e FEATURE_FLAG_CLIENT=config -e AIRBYTE_VERSION=0.50.47 -e WORKER_JOB_ID=71 --cpus=1 --memory-reservation=1Gi --memory=2Gi airbyte/source-file:0.3.15 read --config source_config.json --catalog source_catalog.json
2024-03-01 19:53:12 [46mplatform[0m > Reading messages from protocol version 0.2.0
2024-03-01 19:53:12 [46mplatform[0m > Reading messages from protocol version 0.2.0
2024-03-01 19:53:12 [46mplatform[0m > Starting source heartbeat check. Will check every 1 minutes.
2024-03-01 19:53:12 [46mplatform[0m > readFromSource: start
2024-03-01 19:53:12 [46mplatform[0m > readFromDestination: start
2024-03-01 19:53:12 [46mplatform[0m > writeToDestination: start
2024-03-01 19:53:12 [46mplatform[0m > processMessage: start
2024-03-01 19:53:15 [44msource[0m > Reading scores (https://raw.githubusercontent.com/mlops-itba/Datos-RS/main/data/scores_0.csv)...
2024-03-01 19:53:15 [44msource[0m > TransportParams: None
2024-03-01 19:53:15 [43mdestination[0m > INFO i.a.i.d.p.PostgresDestination(main):98 starting destination: class io.airbyte.integrations.destination.postgres.PostgresDestination
2024-03-01 19:53:15 [43mdestination[0m > INFO i.a.i.b.IntegrationCliParser(parseOptions):126 integration args: {catalog=destination_catalog.json, write=null, config=destination_config.json}
2024-03-01 19:53:15 [43mdestination[0m > INFO i.a.i.b.IntegrationRunner(runInternal):106 Running integration: io.airbyte.integrations.base.ssh.SshWrappedDestination
2024-03-01 19:53:15 [43mdestination[0m > INFO i.a.i.b.IntegrationRunner(runInternal):107 Command: WRITE
2024-03-01 19:53:15 [43mdestination[0m > INFO i.a.i.b.IntegrationRunner(runInternal):108 Integration config: IntegrationConfig{command=WRITE, configPath='destination_config.json', catalogPath='destination_catalog.json', statePath='null'}
2024-03-01 19:53:16 [43mdestination[0m > WARN c.n.s.JsonMetaSchema(newValidator):278 Unknown keyword order - you should define your own Meta Schema. If the keyword is irrelevant for validation, just use a NonValidationKeyword
2024-03-01 19:53:16 [43mdestination[0m > WARN c.n.s.JsonMetaSchema(newValidator):278 Unknown keyword airbyte_secret - you should define your own Meta Schema. If the keyword is irrelevant for validation, just use a NonValidationKeyword
2024-03-01 19:53:16 [43mdestination[0m > INFO i.a.i.b.s.SshTunnel(getInstance):204 Starting connection with method: NO_TUNNEL
2024-03-01 19:53:17 [43mdestination[0m > INFO c.z.h.HikariDataSource(<init>):80 HikariPool-1 - Starting...
2024-03-01 19:53:17 [43mdestination[0m > INFO c.z.h.HikariDataSource(<init>):82 HikariPool-1 - Start completed.
2024-03-01 19:53:17 [43mdestination[0m > INFO i.a.i.d.j.JdbcBufferedConsumerFactory(lambda$toWriteConfig$0):103 Write config: WriteConfig{streamName=scores, namespace=null, outputSchemaName=source, tmpTableName=_airbyte_tmp_thl_scores, outputTableName=_airbyte_raw_scores, syncMode=overwrite}
2024-03-01 19:53:17 [43mdestination[0m > INFO i.a.i.d.b.BufferedStreamConsumer(startTracked):173 class io.airbyte.integrations.destination.buffered_stream_consumer.BufferedStreamConsumer started.
2024-03-01 19:53:17 [43mdestination[0m > INFO i.a.i.d.j.JdbcBufferedConsumerFactory(lambda$onStartFunction$1):142 Preparing raw tables in destination started for 1 streams
2024-03-01 19:53:17 [43mdestination[0m > INFO i.a.i.d.j.JdbcBufferedConsumerFactory(lambda$onStartFunction$1):147 Preparing raw table in destination started for stream scores. schema: source, table name: _airbyte_raw_scores
2024-03-01 19:53:17 [43mdestination[0m > INFO i.a.i.d.j.JdbcBufferedConsumerFactory(lambda$onStartFunction$1):160 Preparing raw tables in destination completed.
2024-03-01 19:53:17 [46mplatform[0m > Records read: 5000 (497 KB)
2024-03-01 19:53:18 [46mplatform[0m > Records read: 10000 (995 KB)
2024-03-01 19:53:18 [46mplatform[0m > Records read: 15000 (1 MB)
2024-03-01 19:53:18 [46mplatform[0m > Records read: 20000 (1 MB)
2024-03-01 19:53:19 [46mplatform[0m > Records read: 25000 (2 MB)
2024-03-01 19:53:19 [46mplatform[0m > Total records read: 25000 (2 MB)
2024-03-01 19:53:19 [46mplatform[0m > Schema validation was performed to a max of 10 records with errors per stream.
2024-03-01 19:53:19 [46mplatform[0m > readFromSource: done. (source.isFinished:true, fromSource.isClosed:false)
2024-03-01 19:53:19 [46mplatform[0m > processMessage: done. (fromSource.isDone:true, forDest.isClosed:false)
2024-03-01 19:53:19 [46mplatform[0m > thread status... heartbeat thread: false , replication thread: true
2024-03-01 19:53:19 [46mplatform[0m > writeToDestination: done. (forDest.isDone:true, isDestRunning:true)
2024-03-01 19:53:19 [46mplatform[0m > thread status... timeout thread: false , replication thread: true
2024-03-01 19:53:19 [43mdestination[0m > INFO i.a.i.b.FailureTrackingAirbyteMessageConsumer(close):80 Airbyte message consumer: succeeded.
2024-03-01 19:53:19 [43mdestination[0m > INFO i.a.i.d.b.BufferedStreamConsumer(close):289 executing on success close procedure.
2024-03-01 19:53:19 [43mdestination[0m > INFO i.a.i.d.r.InMemoryRecordBufferingStrategy(flushAllBuffers):85 Flushing scores: 25000 records (9 MB)
2024-03-01 19:53:20 [43mdestination[0m > INFO i.a.i.d.r.InMemoryRecordBufferingStrategy(flushAllBuffers):91 Flushing completed for scores
2024-03-01 19:53:20 [43mdestination[0m > INFO i.a.i.b.IntegrationRunner(runInternal):197 Completed integration: io.airbyte.integrations.base.ssh.SshWrappedDestination
2024-03-01 19:53:20 [43mdestination[0m > INFO i.a.i.d.p.PostgresDestination(main):100 completed destination: class io.airbyte.integrations.destination.postgres.PostgresDestination
2024-03-01 19:53:20 [46mplatform[0m > readFromDestination: done. (writeToDestFailed:false, dest.isFinished:true)
2024-03-01 19:53:20 [46mplatform[0m > thread status... timeout thread: false , replication thread: true
2024-03-01 19:53:20 [46mplatform[0m > sync summary: {
  "status" : "completed",
  "recordsSynced" : 0,
  "bytesSynced" : 0,
  "startTime" : 1709322792876,
  "endTime" : 1709322800617,
  "totalStats" : {
    "bytesCommitted" : 2548132,
    "bytesEmitted" : 2548132,
    "destinationStateMessagesEmitted" : 0,
    "destinationWriteEndTime" : 1709322800616,
    "destinationWriteStartTime" : 1709322792877,
    "meanSecondsBeforeSourceStateMessageEmitted" : 0,
    "maxSecondsBeforeSourceStateMessageEmitted" : 0,
    "maxSecondsBetweenStateMessageEmittedandCommitted" : 0,
    "meanSecondsBetweenStateMessageEmittedandCommitted" : 0,
    "recordsEmitted" : 25000,
    "recordsCommitted" : 25000,
    "replicationEndTime" : 1709322800617,
    "replicationStartTime" : 1709322792876,
    "sourceReadEndTime" : 1709322799895,
    "sourceReadStartTime" : 1709322792876,
    "sourceStateMessagesEmitted" : 0
  },
  "streamStats" : [ {
    "streamName" : "scores",
    "stats" : {
      "bytesCommitted" : 2548132,
      "bytesEmitted" : 2548132,
      "recordsEmitted" : 25000,
      "recordsCommitted" : 25000
    }
  } ],
  "performanceMetrics" : {
    "processFromSource" : {
      "elapsedTimeInNanos" : 236232756,
      "executionCount" : 25000,
      "avgExecTimeInNanos" : 9449.31024
    },
    "readFromSource" : {
      "elapsedTimeInNanos" : 5160711334,
      "executionCount" : 25154,
      "avgExecTimeInNanos" : 205164.63918263497
    },
    "processFromDest" : {
      "elapsedTimeInNanos" : 0,
      "executionCount" : 0,
      "avgExecTimeInNanos" : "NaN"
    },
    "writeToDest" : {
      "elapsedTimeInNanos" : 1910816785,
      "executionCount" : 25000,
      "avgExecTimeInNanos" : 76432.6714
    },
    "readFromDest" : {
      "elapsedTimeInNanos" : 7703925320,
      "executionCount" : 423,
      "avgExecTimeInNanos" : 1.821258940898345E7
    }
  }
}
2024-03-01 19:53:20 [46mplatform[0m > failures: [ ]
2024-03-01 19:53:20 [46mplatform[0m > 
2024-03-01 19:53:20 [46mplatform[0m > ----- END REPLICATION -----
2024-03-01 19:53:20 [46mplatform[0m > 
2024-03-01 19:53:20 [46mplatform[0m > Docker volume job log path: /tmp/workspace/71/0/logs.log
2024-03-01 19:53:20 [46mplatform[0m > Executing worker wrapper. Airbyte version: 0.50.47
2024-03-01 19:53:20 [46mplatform[0m > Attempt 0 to save workflow id for cancellation
2024-03-01 19:53:20 [46mplatform[0m > 
2024-03-01 19:53:20 [46mplatform[0m > Running with normalization version: airbyte/normalization:0.4.3
2024-03-01 19:53:20 [46mplatform[0m > ----- START DEFAULT NORMALIZATION -----
2024-03-01 19:53:20 [46mplatform[0m > 
2024-03-01 19:53:20 [46mplatform[0m > Checking if airbyte/normalization:0.4.3 exists...
2024-03-01 19:53:20 [46mplatform[0m > airbyte/normalization:0.4.3 was found locally.
2024-03-01 19:53:20 [46mplatform[0m > Creating docker container = normalization-normalize-71-0-mmjqx with resources io.airbyte.config.ResourceRequirements@42547c7f[cpuRequest=,cpuLimit=,memoryRequest=,memoryLimit=,additionalProperties={}] and allowedHosts null
2024-03-01 19:53:20 [46mplatform[0m > Preparing command: docker run --rm --init -i -w /data/71/0/normalize --log-driver none --name normalization-normalize-71-0-mmjqx --network host -v airbyte_workspace:/data -v /tmp/airbyte_local:/local -e DEPLOYMENT_MODE=OSS -e AIRBYTE_ROLE=dev -e WORKER_ENVIRONMENT=DOCKER -e AIRBYTE_VERSION=0.50.47 airbyte/normalization:0.4.3 run --integration-type postgres --config destination_config.json --catalog destination_catalog.json
2024-03-01 19:53:20 [42mnormalization[0m > Running: transform-config --config destination_config.json --integration-type postgres --out /data/71/0/normalize
2024-03-01 19:53:21 [42mnormalization[0m > Namespace(config='destination_config.json', integration_type=<DestinationType.POSTGRES: 'postgres'>, out='/data/71/0/normalize')
2024-03-01 19:53:21 [42mnormalization[0m > transform_postgres
2024-03-01 19:53:21 [42mnormalization[0m > Running: transform-catalog --integration-type postgres --profile-config-dir /data/71/0/normalize --catalog destination_catalog.json --out /data/71/0/normalize/models/generated/ --json-column _airbyte_data
2024-03-01 19:53:21 [42mnormalization[0m > Processing destination_catalog.json...
2024-03-01 19:53:21 [42mnormalization[0m >   Generating airbyte_ctes/source/scores_ab1.sql from scores
2024-03-01 19:53:21 [42mnormalization[0m >   Generating airbyte_ctes/source/scores_ab2.sql from scores
2024-03-01 19:53:21 [42mnormalization[0m >   Generating airbyte_ctes/source/scores_ab3.sql from scores
2024-03-01 19:53:21 [42mnormalization[0m >   Adding drop table hook for scores_scd to scores
2024-03-01 19:53:21 [42mnormalization[0m >   Generating airbyte_tables/source/scores.sql from scores
2024-03-01 19:53:21 [42mnormalization[0m > detected no config file for ssh, assuming ssh is off.
2024-03-01 19:53:23 [42mnormalization[0m >            [--event-buffer-size EVENT_BUFFER_SIZE]
2024-03-01 19:53:23 [42mnormalization[0m >   --event-buffer-size EVENT_BUFFER_SIZE
2024-03-01 19:53:23 [46mplatform[0m > 
2024-03-01 19:53:23 [42mnormalization[0m > DBT >=1.0.0 detected; using 10K event buffer size
2024-03-01 19:53:23 [46mplatform[0m > 
2024-03-01 19:53:25 [42mnormalization[0m > Running with dbt=1.0.0
2024-03-01 19:53:25 [42mnormalization[0m > Partial parse save file not found. Starting full parse.
2024-03-01 19:53:27 [42mnormalization[0m > [[33mWARNING[0m]: Configuration paths exist in your dbt_project.yml file which do not apply to any resources.
There are 2 unused configuration paths:
- models.airbyte_utils.generated.airbyte_incremental
- models.airbyte_utils.generated.airbyte_views

2024-03-01 19:53:27 [42mnormalization[0m > Found 4 models, 0 tests, 0 snapshots, 0 analyses, 599 macros, 0 operations, 0 seed files, 1 source, 0 exposures, 0 metrics
2024-03-01 19:53:27 [42mnormalization[0m > Concurrency: 8 threads (target='prod')
2024-03-01 19:53:27 [42mnormalization[0m > 1 of 1 START table model source.scores.................................................................................. [RUN]
2024-03-01 19:53:27 [42mnormalization[0m > 1 of 1 OK created table model source.scores............................................................................. [[32mSELECT 25000[0m in 0.25s]
2024-03-01 19:53:27 [42mnormalization[0m > Finished running 1 table model in 0.44s.
2024-03-01 19:53:27 [42mnormalization[0m > [32mCompleted successfully[0m
2024-03-01 19:53:27 [42mnormalization[0m > Done. PASS=1 WARN=0 ERROR=0 SKIP=0 TOTAL=1
2024-03-01 19:53:27 [46mplatform[0m > Terminating normalization process...
2024-03-01 19:53:27 [46mplatform[0m > Normalization process successfully terminated.
2024-03-01 19:53:27 [46mplatform[0m > Normalization executed in 7 seconds for job 71.
2024-03-01 19:53:27 [46mplatform[0m > Normalization summary: io.airbyte.config.NormalizationSummary@7dd409cb[startTime=1709322800674,endTime=1709322807751,failures=[],additionalProperties={}]
2024-03-01 19:53:27 [46mplatform[0m > 
2024-03-01 19:53:27 [46mplatform[0m > ----- END DEFAULT NORMALIZATION -----
2024-03-01 19:53:27 [46mplatform[0m > 
